{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import torch\n",
    "import importlib\n",
    "from utils import options\n",
    "from utils.util import log\n",
    "\n",
    "import importlib\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os, sys, time\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import utils.util as util\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from utils.util import log\n",
    "import utils.camera as camera\n",
    "from pipelines import base\n",
    "from pipelines import Camera\n",
    "from pipelines import Point3D\n",
    "from pipelines import Initialization\n",
    "from pipelines import Registration\n",
    "from pipelines import BA\n",
    "from pipelines import rendering_refine\n",
    "from pipelines import Initialization_Trad\n",
    "from pipelines import BA_Trad\n",
    "from pipelines import Registration_Trad\n",
    "from notebooks import vis_3d\n",
    "\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argv = ['--group=ETH3D', '--pipeline=LevelS2fM', '--yaml=ETH3D', '--name=facade', '--data.dataset=ETH3D', '--data.scene=courtyard', '--sfm_mode=full', '--nbv_mode=ours', '--refine_again=false']\n",
    "opt_cmd = options.parse_arguments(argv)\n",
    "opt = options.set(opt_cmd=opt_cmd,safe_check=False)\n",
    "\n",
    "module = importlib.import_module(\"pipelines.{}\".format(opt.pipeline))\n",
    "model_ours = module.Model(opt)\n",
    "model_ours.load_dataset(opt)\n",
    "model_ours.restore_checkpoint(opt)\n",
    "model_ours.setup_visualizer(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = model_ours.load_matches(opt)\n",
    "pose_graph_path = f\"data/{opt.data.dataset}/{opt.data.scene}/pose_graph.npy\"\n",
    "pose_graph = np.load(pose_graph_path, allow_pickle=True)[:]\n",
    "var.indx_init = pose_graph[[0,1]]\n",
    "var.imgs_init = model_ours.train_data.all.image[var.indx_init]\n",
    "var.kypts_init = [var.kypts[i] for i in var.indx_init]\n",
    "var.intrs_init = model_ours.train_data.all.intr[var.indx_init]\n",
    "var.mchs_init = [var.matches[i] for i in var.indx_init]\n",
    "var.inliers_init = [var.masks[i] for i in var.indx_init]\n",
    "var.gt_depths = None\n",
    "var.omn_depths = model_ours.train_data.all.depth_omnidata[var.indx_init]\n",
    "var.omn_norms = model_ours.train_data.all.norm_omnidata[var.indx_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "axes[0].imshow(var.imgs_init[0].permute((1,2,0)).cpu().numpy())\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('The First Image')\n",
    "axes[0].scatter(var.kypts_init[0][:,0].cpu().numpy(), var.kypts_init[0][:,1].cpu().numpy(),s=0.5)\n",
    "axes[1].imshow(var.imgs_init[1].permute((1,2,0)).cpu().numpy())\n",
    "axes[1].scatter(var.kypts_init[1][:,0].cpu().numpy(), var.kypts_init[1][:,1].cpu().numpy(),s=0.5)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('The Second Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initializer_ours = Initialization.Initializer(opt,\n",
    "    model_ours.camera_set,\n",
    "    model_ours.point_set,\n",
    "    model_ours.sdf_func,\n",
    "    model_ours.color_func,\n",
    "    var,cam_info_reloaded=model_ours.cam_info_reloaded)\n",
    "Initializer_ours.run(\n",
    "    model_ours.camera_set,\n",
    "    model_ours.point_set,\n",
    "    model_ours.sdf_func,\n",
    "    model_ours.color_func,\n",
    "    Renderer=model_ours.Renderer,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructed Two-View Point Clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera0 = model_ours.camera_set.cameras[0]\n",
    "camera1 = model_ours.camera_set.cameras[1]\n",
    "pose0 = camera0.get_pose().detach()[0]\n",
    "pose1 = camera1.get_pose().detach()[0]\n",
    "points3D_ours = torch.cat([_.xyz for _ in model_ours.point_set.pointset])\n",
    "\n",
    "fig = vis_3d.init_figure()\n",
    "vis_3d.plot_points(fig, points3D_ours.cpu().numpy(), color='rgba(255,0,255,1)', ps=1, name='Ours')\n",
    "vis_3d.plot_camera(fig, pose0.cpu().numpy()[:3,:3], pose0.cpu().numpy()[:3,3], camera0.intrinsic.cpu().numpy(), color='rgba(0,255,0,1)', name='Camera 0')\n",
    "vis_3d.plot_camera(fig, pose1.cpu().numpy()[:3,:3], pose1.cpu().numpy()[:3,3], camera1.intrinsic.cpu().numpy(), color='rgba(0,128,64,1)', name='Camera 1')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyquaternion\n",
    "\n",
    "def slerp(pose0, pose1, t):\n",
    "    quat0 = pyquaternion.Quaternion._from_matrix(matrix=pose0[:3,:3].cpu().numpy(),rtol=1e-5, atol=1e-5)\n",
    "    quat1 = pyquaternion.Quaternion._from_matrix(matrix=pose1[:3,:3].cpu().numpy(),rtol=1e-5, atol=1e-5)\n",
    "    quatt = pyquaternion.Quaternion.slerp(quat0, quat1, t)\n",
    "    R = torch.tensor(quatt.rotation_matrix,dtype=pose0.dtype,device=pose0.device)\n",
    "    T = (1 - t) * pose0[:3,3] + t * pose1[:3,3]\n",
    "    return torch.cat([R, T[None,:].T], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_seq_rgb = []\n",
    "rendered_seq_depth = []\n",
    "rendered_seq_normal = []\n",
    "height, width = camera0.opt.data.image_size\n",
    "for t in np.linspace(0, 1, 30):\n",
    "    rendered_output = camera0.render_img_by_slices(\n",
    "            model_ours.sdf_func,\n",
    "            model_ours.color_func,\n",
    "            model_ours.Renderer,\n",
    "            slerp(pose0, pose1, t)[None],\n",
    "            )\n",
    "    rendered_rgb = rendered_output['rgb'][0].reshape(height,width,3).cpu().numpy()\n",
    "    rendered_depth = rendered_output['depth'][0].reshape(height,width).cpu().numpy()\n",
    "    rendered_normal = rendered_output['norm'][0].reshape(height,width,3).cpu().numpy()\n",
    "\n",
    "    rendered_seq_rgb.append(rendered_rgb)\n",
    "    rendered_seq_depth.append(rendered_depth)\n",
    "    rendered_seq_normal.append(rendered_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(frames):\n",
    "    from matplotlib.animation import FuncAnimation\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_axis_off()\n",
    "    if frames.dtype == 'float32':\n",
    "        min = np.min(frames)\n",
    "        max = np.max(frames)\n",
    "        if min < 0 or max > 1:\n",
    "            frames = (frames - min) / (max - min)\n",
    "    \n",
    "    im = ax.imshow(frames[0], cmap='gray')\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "    \n",
    "    def update(i):\n",
    "        im.set_data(frames[i])\n",
    "        return im,\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=frames.shape[0], interval=30, blit=True)\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_video = create_animation(np.stack(rendered_seq_rgb,axis=0))\n",
    "depth_video = create_animation(np.stack(rendered_seq_depth,axis=0))\n",
    "normal_video = create_animation(np.stack(rendered_seq_normal,axis=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendered Two-View Videos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(rgb_video.to_jshtml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(depth_video.to_jshtml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(normal_video.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "levels2fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
